{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0acb8fb",
   "metadata": {},
   "source": [
    "# In this notebook, I'll show my implementation of Gradient Descend, and compare its result to the sklearn LinearRegression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735d6fa",
   "metadata": {},
   "source": [
    "## First, A Quick preview on Gradient Descend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843280a6",
   "metadata": {},
   "source": [
    "Gradient Descend is an optimization algorithm to find the best paremeters (slope and interception in case of univariate linear regression), to minimize a cost function, like the mean squared error (MSE), the most used in linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd59873",
   "metadata": {},
   "source": [
    "when drawing the curve between one of the parameters, and the cost function, we'll see that there is a point, a global minimum for the curve, where the cost function is at its lowest, for some value for the said parameter (given the other parameters are constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47c39a",
   "metadata": {},
   "source": [
    "the main idea of gradient descend it to:\n",
    "\n",
    "\n",
    "1- Set a random values for the parameters to improves upon it\n",
    "\n",
    "\n",
    "2- Well, get the gradient (that is, finding the partial derivatives of the cost function with respect to each input variable, which are the parameters),\n",
    "\n",
    "\n",
    "3- Plug the parameters into the gradient\n",
    "\n",
    "\n",
    "4- Multiply it by a learning rate $\\alpha$\tto get the step size, that is, how big of a step the algorithms takes to move in the opposite direction of the gradient (since the gradient is just the slope of the parameter $\\theta$, so we want to go in the direction that causes that slope to become less steep, which means getting closer to the global minimum where the slope is 0) \"the bigger the $\\alpha$, the bigger the step\"\n",
    "\n",
    "5- Calculate the new parameters = old parameter - step size (the minus so that we go in the opposite direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398b131",
   "metadata": {},
   "source": [
    "## We iterate through steps 3 to 5 for a numbers of iteration, or when the cost function gets to some desired value, that's where the algorithm stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107e381",
   "metadata": {},
   "source": [
    "Now, Let's start implementing that said algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: m = 0.0486, b = 0.0095, loss = 19.7922\n",
      "Iteration 2: m = 0.0967, b = 0.0189, loss = 19.5482\n",
      "Iteration 3: m = 0.1443, b = 0.0283, loss = 19.3093\n",
      "Iteration 4: m = 0.1914, b = 0.0375, loss = 19.0752\n",
      "Iteration 5: m = 0.2380, b = 0.0466, loss = 18.8460\n",
      "Iteration 6: m = 0.2842, b = 0.0556, loss = 18.6214\n",
      "Iteration 7: m = 0.3299, b = 0.0645, loss = 18.4015\n",
      "Iteration 8: m = 0.3751, b = 0.0733, loss = 18.1860\n",
      "Iteration 9: m = 0.4198, b = 0.0820, loss = 17.9750\n",
      "Iteration 10: m = 0.4641, b = 0.0906, loss = 17.7683\n",
      "Iteration 11: m = 0.5079, b = 0.0992, loss = 17.5658\n",
      "Iteration 12: m = 0.5513, b = 0.1076, loss = 17.3674\n",
      "Iteration 13: m = 0.5942, b = 0.1159, loss = 17.1732\n",
      "Iteration 14: m = 0.6367, b = 0.1241, loss = 16.9829\n",
      "Iteration 15: m = 0.6788, b = 0.1323, loss = 16.7965\n",
      "Iteration 16: m = 0.7204, b = 0.1403, loss = 16.6139\n",
      "Iteration 17: m = 0.7616, b = 0.1483, loss = 16.4350\n",
      "Iteration 18: m = 0.8024, b = 0.1562, loss = 16.2599\n",
      "Iteration 19: m = 0.8428, b = 0.1640, loss = 16.0883\n",
      "Iteration 20: m = 0.8827, b = 0.1717, loss = 15.9202\n",
      "Iteration 21: m = 0.9222, b = 0.1793, loss = 15.7555\n",
      "Iteration 22: m = 0.9614, b = 0.1868, loss = 15.5943\n",
      "Iteration 23: m = 1.0001, b = 0.1943, loss = 15.4363\n",
      "Iteration 24: m = 1.0384, b = 0.2016, loss = 15.2816\n",
      "Iteration 25: m = 1.0764, b = 0.2089, loss = 15.1300\n",
      "Iteration 26: m = 1.1139, b = 0.2161, loss = 14.9816\n",
      "Iteration 27: m = 1.1511, b = 0.2232, loss = 14.8361\n",
      "Iteration 28: m = 1.1878, b = 0.2303, loss = 14.6937\n",
      "Iteration 29: m = 1.2243, b = 0.2372, loss = 14.5542\n",
      "Iteration 30: m = 1.2603, b = 0.2441, loss = 14.4175\n",
      "Iteration 31: m = 1.2959, b = 0.2509, loss = 14.2837\n",
      "Iteration 32: m = 1.3312, b = 0.2576, loss = 14.1525\n",
      "Iteration 33: m = 1.3662, b = 0.2643, loss = 14.0241\n",
      "Iteration 34: m = 1.4007, b = 0.2709, loss = 13.8983\n",
      "Iteration 35: m = 1.4350, b = 0.2774, loss = 13.7750\n",
      "Iteration 36: m = 1.4688, b = 0.2838, loss = 13.6543\n",
      "Iteration 37: m = 1.5024, b = 0.2902, loss = 13.5361\n",
      "Iteration 38: m = 1.5355, b = 0.2965, loss = 13.4203\n",
      "Iteration 39: m = 1.5684, b = 0.3027, loss = 13.3068\n",
      "Iteration 40: m = 1.6009, b = 0.3089, loss = 13.1957\n",
      "Iteration 41: m = 1.6330, b = 0.3149, loss = 13.0869\n",
      "Iteration 42: m = 1.6649, b = 0.3210, loss = 12.9802\n",
      "Iteration 43: m = 1.6964, b = 0.3269, loss = 12.8758\n",
      "Iteration 44: m = 1.7276, b = 0.3328, loss = 12.7735\n",
      "Iteration 45: m = 1.7584, b = 0.3386, loss = 12.6733\n",
      "Iteration 46: m = 1.7890, b = 0.3444, loss = 12.5751\n",
      "Iteration 47: m = 1.8192, b = 0.3500, loss = 12.4790\n",
      "Iteration 48: m = 1.8492, b = 0.3557, loss = 12.3848\n",
      "Iteration 49: m = 1.8788, b = 0.3612, loss = 12.2926\n",
      "Iteration 50: m = 1.9081, b = 0.3667, loss = 12.2022\n",
      "Iteration 51: m = 1.9371, b = 0.3722, loss = 12.1137\n",
      "Iteration 52: m = 1.9658, b = 0.3775, loss = 12.0270\n",
      "Iteration 53: m = 1.9942, b = 0.3829, loss = 11.9421\n",
      "Iteration 54: m = 2.0224, b = 0.3881, loss = 11.8589\n",
      "Iteration 55: m = 2.0502, b = 0.3933, loss = 11.7775\n",
      "Iteration 56: m = 2.0778, b = 0.3984, loss = 11.6976\n",
      "Iteration 57: m = 2.1050, b = 0.4035, loss = 11.6195\n",
      "Iteration 58: m = 2.1320, b = 0.4086, loss = 11.5429\n",
      "Iteration 59: m = 2.1588, b = 0.4135, loss = 11.4679\n",
      "Iteration 60: m = 2.1852, b = 0.4184, loss = 11.3944\n",
      "Iteration 61: m = 2.2114, b = 0.4233, loss = 11.3224\n",
      "Iteration 62: m = 2.2373, b = 0.4281, loss = 11.2520\n",
      "Iteration 63: m = 2.2629, b = 0.4329, loss = 11.1829\n",
      "Iteration 64: m = 2.2883, b = 0.4375, loss = 11.1153\n",
      "Iteration 65: m = 2.3134, b = 0.4422, loss = 11.0490\n",
      "Iteration 66: m = 2.3383, b = 0.4468, loss = 10.9841\n",
      "Iteration 67: m = 2.3629, b = 0.4513, loss = 10.9206\n",
      "Iteration 68: m = 2.3872, b = 0.4558, loss = 10.8583\n",
      "Iteration 69: m = 2.4113, b = 0.4603, loss = 10.7973\n",
      "Iteration 70: m = 2.4352, b = 0.4646, loss = 10.7376\n",
      "Iteration 71: m = 2.4588, b = 0.4690, loss = 10.6790\n",
      "Iteration 72: m = 2.4821, b = 0.4733, loss = 10.6217\n",
      "Iteration 73: m = 2.5053, b = 0.4775, loss = 10.5656\n",
      "Iteration 74: m = 2.5282, b = 0.4817, loss = 10.5106\n",
      "Iteration 75: m = 2.5508, b = 0.4859, loss = 10.4567\n",
      "Iteration 76: m = 2.5732, b = 0.4900, loss = 10.4039\n",
      "Iteration 77: m = 2.5954, b = 0.4940, loss = 10.3522\n",
      "Iteration 78: m = 2.6174, b = 0.4980, loss = 10.3016\n",
      "Iteration 79: m = 2.6391, b = 0.5020, loss = 10.2520\n",
      "Iteration 80: m = 2.6606, b = 0.5059, loss = 10.2034\n",
      "Iteration 81: m = 2.6819, b = 0.5098, loss = 10.1559\n",
      "Iteration 82: m = 2.7030, b = 0.5136, loss = 10.1092\n",
      "Iteration 83: m = 2.7239, b = 0.5174, loss = 10.0636\n",
      "Iteration 84: m = 2.7445, b = 0.5212, loss = 10.0189\n",
      "Iteration 85: m = 2.7649, b = 0.5249, loss = 9.9751\n",
      "Iteration 86: m = 2.7852, b = 0.5286, loss = 9.9322\n",
      "Iteration 87: m = 2.8052, b = 0.5322, loss = 9.8901\n",
      "Iteration 88: m = 2.8250, b = 0.5358, loss = 9.8490\n",
      "Iteration 89: m = 2.8446, b = 0.5393, loss = 9.8086\n",
      "Iteration 90: m = 2.8640, b = 0.5428, loss = 9.7691\n",
      "Iteration 91: m = 2.8832, b = 0.5463, loss = 9.7304\n",
      "Iteration 92: m = 2.9022, b = 0.5497, loss = 9.6925\n",
      "Iteration 93: m = 2.9211, b = 0.5531, loss = 9.6554\n",
      "Iteration 94: m = 2.9397, b = 0.5564, loss = 9.6190\n",
      "Iteration 95: m = 2.9581, b = 0.5598, loss = 9.5834\n",
      "Iteration 96: m = 2.9764, b = 0.5630, loss = 9.5485\n",
      "Iteration 97: m = 2.9944, b = 0.5663, loss = 9.5143\n",
      "Iteration 98: m = 3.0123, b = 0.5695, loss = 9.4809\n",
      "Iteration 99: m = 3.0300, b = 0.5726, loss = 9.4481\n",
      "Iteration 100: m = 3.0475, b = 0.5758, loss = 9.4160\n",
      "Iteration 101: m = 3.0648, b = 0.5789, loss = 9.3845\n",
      "Iteration 102: m = 3.0820, b = 0.5819, loss = 9.3537\n",
      "Iteration 103: m = 3.0989, b = 0.5849, loss = 9.3235\n",
      "Iteration 104: m = 3.1157, b = 0.5879, loss = 9.2939\n",
      "Iteration 105: m = 3.1324, b = 0.5909, loss = 9.2649\n",
      "Iteration 106: m = 3.1488, b = 0.5938, loss = 9.2366\n",
      "Iteration 107: m = 3.1651, b = 0.5967, loss = 9.2088\n",
      "Iteration 108: m = 3.1812, b = 0.5996, loss = 9.1816\n",
      "Iteration 109: m = 3.1972, b = 0.6024, loss = 9.1549\n",
      "Iteration 110: m = 3.2130, b = 0.6052, loss = 9.1288\n",
      "Iteration 111: m = 3.2286, b = 0.6080, loss = 9.1032\n",
      "Iteration 112: m = 3.2441, b = 0.6107, loss = 9.0781\n",
      "Iteration 113: m = 3.2594, b = 0.6134, loss = 9.0536\n",
      "Iteration 114: m = 3.2745, b = 0.6161, loss = 9.0295\n",
      "Iteration 115: m = 3.2895, b = 0.6187, loss = 9.0060\n",
      "Iteration 116: m = 3.3044, b = 0.6213, loss = 8.9829\n",
      "Iteration 117: m = 3.3191, b = 0.6239, loss = 8.9603\n",
      "Iteration 118: m = 3.3336, b = 0.6264, loss = 8.9382\n",
      "Iteration 119: m = 3.3480, b = 0.6290, loss = 8.9165\n",
      "Iteration 120: m = 3.3622, b = 0.6315, loss = 8.8952\n",
      "Iteration 121: m = 3.3763, b = 0.6339, loss = 8.8744\n",
      "Iteration 122: m = 3.3903, b = 0.6364, loss = 8.8541\n",
      "Iteration 123: m = 3.4041, b = 0.6388, loss = 8.8341\n",
      "Iteration 124: m = 3.4178, b = 0.6412, loss = 8.8145\n",
      "Iteration 125: m = 3.4313, b = 0.6435, loss = 8.7954\n",
      "Iteration 126: m = 3.4447, b = 0.6459, loss = 8.7766\n",
      "Iteration 127: m = 3.4579, b = 0.6482, loss = 8.7582\n",
      "Iteration 128: m = 3.4711, b = 0.6504, loss = 8.7402\n",
      "Iteration 129: m = 3.4840, b = 0.6527, loss = 8.7226\n",
      "Iteration 130: m = 3.4969, b = 0.6549, loss = 8.7053\n",
      "Iteration 131: m = 3.5096, b = 0.6571, loss = 8.6884\n",
      "Iteration 132: m = 3.5222, b = 0.6593, loss = 8.6718\n",
      "Iteration 133: m = 3.5346, b = 0.6615, loss = 8.6556\n",
      "Iteration 134: m = 3.5470, b = 0.6636, loss = 8.6397\n",
      "Iteration 135: m = 3.5592, b = 0.6657, loss = 8.6241\n",
      "Iteration 136: m = 3.5713, b = 0.6678, loss = 8.6089\n",
      "Iteration 137: m = 3.5832, b = 0.6698, loss = 8.5939\n",
      "Iteration 138: m = 3.5950, b = 0.6719, loss = 8.5793\n",
      "Iteration 139: m = 3.6068, b = 0.6739, loss = 8.5650\n",
      "Iteration 140: m = 3.6183, b = 0.6759, loss = 8.5509\n",
      "Iteration 141: m = 3.6298, b = 0.6778, loss = 8.5371\n",
      "Iteration 142: m = 3.6412, b = 0.6798, loss = 8.5237\n",
      "Iteration 143: m = 3.6524, b = 0.6817, loss = 8.5105\n",
      "Iteration 144: m = 3.6635, b = 0.6836, loss = 8.4975\n",
      "Iteration 145: m = 3.6745, b = 0.6855, loss = 8.4849\n",
      "Iteration 146: m = 3.6854, b = 0.6874, loss = 8.4725\n",
      "Iteration 147: m = 3.6962, b = 0.6892, loss = 8.4603\n",
      "Iteration 148: m = 3.7069, b = 0.6910, loss = 8.4484\n",
      "Iteration 149: m = 3.7175, b = 0.6928, loss = 8.4367\n",
      "Iteration 150: m = 3.7279, b = 0.6946, loss = 8.4253\n",
      "Iteration 151: m = 3.7383, b = 0.6963, loss = 8.4141\n",
      "Iteration 152: m = 3.7485, b = 0.6981, loss = 8.4032\n",
      "Iteration 153: m = 3.7586, b = 0.6998, loss = 8.3924\n",
      "Iteration 154: m = 3.7687, b = 0.7015, loss = 8.3819\n",
      "Iteration 155: m = 3.7786, b = 0.7032, loss = 8.3716\n",
      "Iteration 156: m = 3.7884, b = 0.7048, loss = 8.3615\n",
      "Iteration 157: m = 3.7982, b = 0.7065, loss = 8.3516\n",
      "Iteration 158: m = 3.8078, b = 0.7081, loss = 8.3420\n",
      "Iteration 159: m = 3.8173, b = 0.7097, loss = 8.3325\n",
      "Iteration 160: m = 3.8267, b = 0.7113, loss = 8.3232\n",
      "Iteration 161: m = 3.8361, b = 0.7128, loss = 8.3141\n",
      "Iteration 162: m = 3.8453, b = 0.7144, loss = 8.3052\n",
      "Iteration 163: m = 3.8545, b = 0.7159, loss = 8.2965\n",
      "Iteration 164: m = 3.8635, b = 0.7174, loss = 8.2879\n",
      "Iteration 165: m = 3.8725, b = 0.7189, loss = 8.2795\n",
      "Iteration 166: m = 3.8813, b = 0.7204, loss = 8.2713\n",
      "Iteration 167: m = 3.8901, b = 0.7219, loss = 8.2633\n",
      "Iteration 168: m = 3.8988, b = 0.7233, loss = 8.2554\n",
      "Iteration 169: m = 3.9074, b = 0.7248, loss = 8.2477\n",
      "Iteration 170: m = 3.9159, b = 0.7262, loss = 8.2401\n",
      "Iteration 171: m = 3.9243, b = 0.7276, loss = 8.2327\n",
      "Iteration 172: m = 3.9327, b = 0.7289, loss = 8.2255\n",
      "Iteration 173: m = 3.9409, b = 0.7303, loss = 8.2184\n",
      "Iteration 174: m = 3.9491, b = 0.7317, loss = 8.2114\n",
      "Iteration 175: m = 3.9571, b = 0.7330, loss = 8.2046\n",
      "Iteration 176: m = 3.9651, b = 0.7343, loss = 8.1980\n",
      "Iteration 177: m = 3.9731, b = 0.7356, loss = 8.1914\n",
      "Iteration 178: m = 3.9809, b = 0.7369, loss = 8.1850\n",
      "Iteration 179: m = 3.9886, b = 0.7382, loss = 8.1787\n",
      "Iteration 180: m = 3.9963, b = 0.7395, loss = 8.1726\n",
      "Iteration 181: m = 4.0039, b = 0.7407, loss = 8.1666\n",
      "Iteration 182: m = 4.0114, b = 0.7419, loss = 8.1607\n",
      "Iteration 183: m = 4.0189, b = 0.7432, loss = 8.1549\n",
      "Iteration 184: m = 4.0262, b = 0.7444, loss = 8.1493\n",
      "Iteration 185: m = 4.0335, b = 0.7456, loss = 8.1437\n",
      "Iteration 186: m = 4.0407, b = 0.7467, loss = 8.1383\n",
      "Iteration 187: m = 4.0479, b = 0.7479, loss = 8.1330\n",
      "Iteration 188: m = 4.0549, b = 0.7490, loss = 8.1278\n",
      "Iteration 189: m = 4.0619, b = 0.7502, loss = 8.1227\n",
      "Iteration 190: m = 4.0689, b = 0.7513, loss = 8.1177\n",
      "Iteration 191: m = 4.0757, b = 0.7524, loss = 8.1128\n",
      "Iteration 192: m = 4.0825, b = 0.7535, loss = 8.1080\n",
      "Iteration 193: m = 4.0892, b = 0.7546, loss = 8.1033\n",
      "Iteration 194: m = 4.0959, b = 0.7557, loss = 8.0987\n",
      "Iteration 195: m = 4.1024, b = 0.7568, loss = 8.0942\n",
      "Iteration 196: m = 4.1089, b = 0.7578, loss = 8.0898\n",
      "Iteration 197: m = 4.1154, b = 0.7588, loss = 8.0854\n",
      "Iteration 198: m = 4.1218, b = 0.7599, loss = 8.0812\n",
      "Iteration 199: m = 4.1281, b = 0.7609, loss = 8.0771\n",
      "Iteration 200: m = 4.1343, b = 0.7619, loss = 8.0730\n",
      "Iteration 201: m = 4.1405, b = 0.7629, loss = 8.0690\n",
      "Iteration 202: m = 4.1466, b = 0.7639, loss = 8.0651\n",
      "Iteration 203: m = 4.1527, b = 0.7648, loss = 8.0613\n",
      "Iteration 204: m = 4.1587, b = 0.7658, loss = 8.0576\n",
      "Iteration 205: m = 4.1646, b = 0.7667, loss = 8.0539\n",
      "Iteration 206: m = 4.1705, b = 0.7677, loss = 8.0503\n",
      "Iteration 207: m = 4.1763, b = 0.7686, loss = 8.0468\n",
      "Iteration 208: m = 4.1820, b = 0.7695, loss = 8.0434\n",
      "Iteration 209: m = 4.1877, b = 0.7704, loss = 8.0400\n",
      "Iteration 210: m = 4.1933, b = 0.7713, loss = 8.0367\n",
      "Iteration 211: m = 4.1989, b = 0.7722, loss = 8.0334\n",
      "Iteration 212: m = 4.2044, b = 0.7731, loss = 8.0303\n",
      "Iteration 213: m = 4.2099, b = 0.7739, loss = 8.0272\n",
      "Iteration 214: m = 4.2153, b = 0.7748, loss = 8.0241\n",
      "Iteration 215: m = 4.2206, b = 0.7756, loss = 8.0211\n",
      "Iteration 216: m = 4.2259, b = 0.7765, loss = 8.0182\n",
      "Iteration 217: m = 4.2312, b = 0.7773, loss = 8.0154\n",
      "Iteration 218: m = 4.2364, b = 0.7781, loss = 8.0126\n",
      "Iteration 219: m = 4.2415, b = 0.7789, loss = 8.0098\n",
      "Iteration 220: m = 4.2466, b = 0.7797, loss = 8.0071\n",
      "Iteration 221: m = 4.2516, b = 0.7805, loss = 8.0045\n",
      "Iteration 222: m = 4.2566, b = 0.7813, loss = 8.0019\n",
      "Iteration 223: m = 4.2615, b = 0.7821, loss = 7.9994\n",
      "Iteration 224: m = 4.2664, b = 0.7828, loss = 7.9969\n",
      "Iteration 225: m = 4.2712, b = 0.7836, loss = 7.9945\n",
      "Iteration 226: m = 4.2760, b = 0.7843, loss = 7.9921\n",
      "Iteration 227: m = 4.2807, b = 0.7851, loss = 7.9898\n",
      "Iteration 228: m = 4.2854, b = 0.7858, loss = 7.9875\n",
      "Iteration 229: m = 4.2900, b = 0.7865, loss = 7.9853\n",
      "Iteration 230: m = 4.2946, b = 0.7872, loss = 7.9831\n",
      "Iteration 231: m = 4.2992, b = 0.7879, loss = 7.9810\n",
      "Iteration 232: m = 4.3037, b = 0.7886, loss = 7.9789\n",
      "Iteration 233: m = 4.3081, b = 0.7893, loss = 7.9768\n",
      "Iteration 234: m = 4.3125, b = 0.7900, loss = 7.9748\n",
      "Iteration 235: m = 4.3169, b = 0.7907, loss = 7.9728\n",
      "Iteration 236: m = 4.3212, b = 0.7913, loss = 7.9709\n",
      "Iteration 237: m = 4.3254, b = 0.7920, loss = 7.9690\n",
      "Iteration 238: m = 4.3296, b = 0.7926, loss = 7.9671\n",
      "Iteration 239: m = 4.3338, b = 0.7933, loss = 7.9653\n",
      "Iteration 240: m = 4.3380, b = 0.7939, loss = 7.9636\n",
      "Iteration 241: m = 4.3421, b = 0.7945, loss = 7.9618\n",
      "Iteration 242: m = 4.3461, b = 0.7952, loss = 7.9601\n",
      "Iteration 243: m = 4.3501, b = 0.7958, loss = 7.9584\n",
      "Iteration 244: m = 4.3541, b = 0.7964, loss = 7.9568\n",
      "Iteration 245: m = 4.3580, b = 0.7970, loss = 7.9552\n",
      "Iteration 246: m = 4.3619, b = 0.7976, loss = 7.9536\n",
      "Iteration 247: m = 4.3657, b = 0.7982, loss = 7.9521\n",
      "Iteration 248: m = 4.3696, b = 0.7987, loss = 7.9506\n",
      "Iteration 249: m = 4.3733, b = 0.7993, loss = 7.9491\n",
      "Iteration 250: m = 4.3771, b = 0.7999, loss = 7.9477\n",
      "Iteration 251: m = 4.3807, b = 0.8004, loss = 7.9462\n",
      "Iteration 252: m = 4.3844, b = 0.8010, loss = 7.9449\n",
      "Iteration 253: m = 4.3880, b = 0.8015, loss = 7.9435\n",
      "Iteration 254: m = 4.3916, b = 0.8021, loss = 7.9422\n",
      "Iteration 255: m = 4.3951, b = 0.8026, loss = 7.9409\n",
      "Iteration 256: m = 4.3986, b = 0.8031, loss = 7.9396\n",
      "Iteration 257: m = 4.4021, b = 0.8037, loss = 7.9383\n",
      "Iteration 258: m = 4.4055, b = 0.8042, loss = 7.9371\n",
      "Iteration 259: m = 4.4089, b = 0.8047, loss = 7.9359\n",
      "Iteration 260: m = 4.4123, b = 0.8052, loss = 7.9347\n",
      "Iteration 261: m = 4.4156, b = 0.8057, loss = 7.9336\n",
      "Iteration 262: m = 4.4189, b = 0.8062, loss = 7.9325\n",
      "Iteration 263: m = 4.4222, b = 0.8067, loss = 7.9314\n",
      "Iteration 264: m = 4.4254, b = 0.8071, loss = 7.9303\n",
      "Iteration 265: m = 4.4286, b = 0.8076, loss = 7.9292\n",
      "Iteration 266: m = 4.4318, b = 0.8081, loss = 7.9282\n",
      "Iteration 267: m = 4.4349, b = 0.8086, loss = 7.9272\n",
      "Iteration 268: m = 4.4380, b = 0.8090, loss = 7.9262\n",
      "Iteration 269: m = 4.4411, b = 0.8095, loss = 7.9252\n",
      "Iteration 270: m = 4.4441, b = 0.8099, loss = 7.9242\n",
      "Iteration 271: m = 4.4471, b = 0.8104, loss = 7.9233\n",
      "Iteration 272: m = 4.4501, b = 0.8108, loss = 7.9224\n",
      "Iteration 273: m = 4.4530, b = 0.8112, loss = 7.9215\n",
      "Iteration 274: m = 4.4560, b = 0.8117, loss = 7.9206\n",
      "Iteration 275: m = 4.4588, b = 0.8121, loss = 7.9197\n",
      "Iteration 276: m = 4.4617, b = 0.8125, loss = 7.9189\n",
      "Iteration 277: m = 4.4645, b = 0.8129, loss = 7.9181\n",
      "Iteration 278: m = 4.4673, b = 0.8133, loss = 7.9172\n",
      "Iteration 279: m = 4.4701, b = 0.8137, loss = 7.9164\n",
      "Iteration 280: m = 4.4728, b = 0.8141, loss = 7.9157\n",
      "Iteration 281: m = 4.4755, b = 0.8145, loss = 7.9149\n",
      "Iteration 282: m = 4.4782, b = 0.8149, loss = 7.9142\n",
      "Iteration 283: m = 4.4809, b = 0.8153, loss = 7.9134\n",
      "Iteration 284: m = 4.4835, b = 0.8157, loss = 7.9127\n",
      "Iteration 285: m = 4.4861, b = 0.8161, loss = 7.9120\n",
      "Iteration 286: m = 4.4887, b = 0.8164, loss = 7.9113\n",
      "Iteration 287: m = 4.4912, b = 0.8168, loss = 7.9107\n",
      "Iteration 288: m = 4.4937, b = 0.8172, loss = 7.9100\n",
      "Iteration 289: m = 4.4962, b = 0.8175, loss = 7.9093\n",
      "Iteration 290: m = 4.4987, b = 0.8179, loss = 7.9087\n",
      "Iteration 291: m = 4.5012, b = 0.8182, loss = 7.9081\n",
      "Iteration 292: m = 4.5036, b = 0.8186, loss = 7.9075\n",
      "Iteration 293: m = 4.5060, b = 0.8189, loss = 7.9069\n",
      "Iteration 294: m = 4.5083, b = 0.8193, loss = 7.9063\n",
      "Iteration 295: m = 4.5107, b = 0.8196, loss = 7.9057\n",
      "Iteration 296: m = 4.5130, b = 0.8199, loss = 7.9052\n",
      "Iteration 297: m = 4.5153, b = 0.8203, loss = 7.9046\n",
      "Iteration 298: m = 4.5176, b = 0.8206, loss = 7.9041\n",
      "Iteration 299: m = 4.5198, b = 0.8209, loss = 7.9036\n",
      "Iteration 300: m = 4.5221, b = 0.8212, loss = 7.9031\n",
      "Iteration 301: m = 4.5243, b = 0.8215, loss = 7.9026\n",
      "Iteration 302: m = 4.5264, b = 0.8219, loss = 7.9021\n",
      "Iteration 303: m = 4.5286, b = 0.8222, loss = 7.9016\n",
      "Iteration 304: m = 4.5307, b = 0.8225, loss = 7.9011\n",
      "Iteration 305: m = 4.5329, b = 0.8228, loss = 7.9006\n",
      "Iteration 306: m = 4.5350, b = 0.8231, loss = 7.9002\n",
      "Iteration 307: m = 4.5370, b = 0.8234, loss = 7.8997\n",
      "Iteration 308: m = 4.5391, b = 0.8236, loss = 7.8993\n",
      "Iteration 309: m = 4.5411, b = 0.8239, loss = 7.8989\n",
      "Iteration 310: m = 4.5431, b = 0.8242, loss = 7.8985\n",
      "Iteration 311: m = 4.5451, b = 0.8245, loss = 7.8980\n",
      "Iteration 312: m = 4.5471, b = 0.8248, loss = 7.8976\n",
      "Iteration 313: m = 4.5490, b = 0.8250, loss = 7.8973\n",
      "Iteration 314: m = 4.5510, b = 0.8253, loss = 7.8969\n",
      "Iteration 315: m = 4.5529, b = 0.8256, loss = 7.8965\n",
      "Iteration 316: m = 4.5548, b = 0.8258, loss = 7.8961\n",
      "Iteration 317: m = 4.5566, b = 0.8261, loss = 7.8958\n",
      "Iteration 318: m = 4.5585, b = 0.8264, loss = 7.8954\n",
      "Iteration 319: m = 4.5603, b = 0.8266, loss = 7.8951\n",
      "Iteration 320: m = 4.5621, b = 0.8269, loss = 7.8947\n",
      "Iteration 321: m = 4.5639, b = 0.8271, loss = 7.8944\n",
      "Iteration 322: m = 4.5657, b = 0.8274, loss = 7.8941\n",
      "Iteration 323: m = 4.5675, b = 0.8276, loss = 7.8937\n",
      "Iteration 324: m = 4.5692, b = 0.8278, loss = 7.8934\n",
      "Iteration 325: m = 4.5709, b = 0.8281, loss = 7.8931\n",
      "Iteration 326: m = 4.5726, b = 0.8283, loss = 7.8928\n",
      "Iteration 327: m = 4.5743, b = 0.8285, loss = 7.8925\n",
      "Iteration 328: m = 4.5760, b = 0.8288, loss = 7.8922\n",
      "Iteration 329: m = 4.5776, b = 0.8290, loss = 7.8919\n",
      "Iteration 330: m = 4.5793, b = 0.8292, loss = 7.8917\n",
      "Iteration 331: m = 4.5809, b = 0.8294, loss = 7.8914\n",
      "Iteration 332: m = 4.5825, b = 0.8297, loss = 7.8911\n",
      "Iteration 333: m = 4.5841, b = 0.8299, loss = 7.8909\n",
      "Iteration 334: m = 4.5857, b = 0.8301, loss = 7.8906\n",
      "Iteration 335: m = 4.5872, b = 0.8303, loss = 7.8904\n",
      "Iteration 336: m = 4.5887, b = 0.8305, loss = 7.8901\n",
      "Iteration 337: m = 4.5903, b = 0.8307, loss = 7.8899\n",
      "Iteration 338: m = 4.5918, b = 0.8309, loss = 7.8896\n",
      "Iteration 339: m = 4.5933, b = 0.8311, loss = 7.8894\n",
      "Iteration 340: m = 4.5947, b = 0.8313, loss = 7.8892\n",
      "Iteration 341: m = 4.5962, b = 0.8315, loss = 7.8890\n",
      "Iteration 342: m = 4.5976, b = 0.8317, loss = 7.8888\n",
      "Iteration 343: m = 4.5991, b = 0.8319, loss = 7.8885\n",
      "Iteration 344: m = 4.6005, b = 0.8321, loss = 7.8883\n",
      "Iteration 345: m = 4.6019, b = 0.8323, loss = 7.8881\n",
      "Iteration 346: m = 4.6033, b = 0.8325, loss = 7.8879\n",
      "Iteration 347: m = 4.6047, b = 0.8326, loss = 7.8877\n",
      "Iteration 348: m = 4.6060, b = 0.8328, loss = 7.8875\n",
      "Iteration 349: m = 4.6074, b = 0.8330, loss = 7.8874\n",
      "Iteration 350: m = 4.6087, b = 0.8332, loss = 7.8872\n",
      "Iteration 351: m = 4.6100, b = 0.8334, loss = 7.8870\n",
      "Iteration 352: m = 4.6113, b = 0.8335, loss = 7.8868\n",
      "Iteration 353: m = 4.6126, b = 0.8337, loss = 7.8867\n",
      "Iteration 354: m = 4.6139, b = 0.8339, loss = 7.8865\n",
      "Iteration 355: m = 4.6152, b = 0.8340, loss = 7.8863\n",
      "Iteration 356: m = 4.6164, b = 0.8342, loss = 7.8862\n",
      "Iteration 357: m = 4.6176, b = 0.8344, loss = 7.8860\n",
      "Iteration 358: m = 4.6189, b = 0.8345, loss = 7.8858\n",
      "Iteration 359: m = 4.6201, b = 0.8347, loss = 7.8857\n",
      "Iteration 360: m = 4.6213, b = 0.8348, loss = 7.8855\n",
      "Iteration 361: m = 4.6225, b = 0.8350, loss = 7.8854\n",
      "Iteration 362: m = 4.6236, b = 0.8351, loss = 7.8853\n",
      "Iteration 363: m = 4.6248, b = 0.8353, loss = 7.8851\n",
      "Iteration 364: m = 4.6260, b = 0.8354, loss = 7.8850\n",
      "Iteration 365: m = 4.6271, b = 0.8356, loss = 7.8848\n",
      "Iteration 366: m = 4.6282, b = 0.8357, loss = 7.8847\n",
      "Iteration 367: m = 4.6294, b = 0.8359, loss = 7.8846\n",
      "Iteration 368: m = 4.6305, b = 0.8360, loss = 7.8845\n",
      "Iteration 369: m = 4.6316, b = 0.8362, loss = 7.8843\n",
      "Iteration 370: m = 4.6326, b = 0.8363, loss = 7.8842\n",
      "Iteration 371: m = 4.6337, b = 0.8364, loss = 7.8841\n",
      "Iteration 372: m = 4.6348, b = 0.8366, loss = 7.8840\n",
      "Iteration 373: m = 4.6358, b = 0.8367, loss = 7.8839\n",
      "Iteration 374: m = 4.6369, b = 0.8369, loss = 7.8837\n",
      "Iteration 375: m = 4.6379, b = 0.8370, loss = 7.8836\n",
      "Iteration 376: m = 4.6389, b = 0.8371, loss = 7.8835\n",
      "Iteration 377: m = 4.6399, b = 0.8372, loss = 7.8834\n",
      "Iteration 378: m = 4.6409, b = 0.8374, loss = 7.8833\n",
      "Iteration 379: m = 4.6419, b = 0.8375, loss = 7.8832\n",
      "Iteration 380: m = 4.6429, b = 0.8376, loss = 7.8831\n",
      "Iteration 381: m = 4.6438, b = 0.8377, loss = 7.8830\n",
      "Iteration 382: m = 4.6448, b = 0.8379, loss = 7.8829\n",
      "Iteration 383: m = 4.6458, b = 0.8380, loss = 7.8828\n",
      "Iteration 384: m = 4.6467, b = 0.8381, loss = 7.8827\n",
      "Iteration 385: m = 4.6476, b = 0.8382, loss = 7.8827\n",
      "Iteration 386: m = 4.6485, b = 0.8383, loss = 7.8826\n",
      "Iteration 387: m = 4.6494, b = 0.8384, loss = 7.8825\n",
      "Iteration 388: m = 4.6503, b = 0.8386, loss = 7.8824\n",
      "Iteration 389: m = 4.6512, b = 0.8387, loss = 7.8823\n",
      "Iteration 390: m = 4.6521, b = 0.8388, loss = 7.8822\n",
      "Iteration 391: m = 4.6530, b = 0.8389, loss = 7.8822\n",
      "Iteration 392: m = 4.6539, b = 0.8390, loss = 7.8821\n",
      "Iteration 393: m = 4.6547, b = 0.8391, loss = 7.8820\n",
      "Iteration 394: m = 4.6556, b = 0.8392, loss = 7.8819\n",
      "Iteration 395: m = 4.6564, b = 0.8393, loss = 7.8819\n",
      "Iteration 396: m = 4.6572, b = 0.8394, loss = 7.8818\n",
      "Iteration 397: m = 4.6580, b = 0.8395, loss = 7.8817\n",
      "Iteration 398: m = 4.6589, b = 0.8396, loss = 7.8817\n",
      "Iteration 399: m = 4.6597, b = 0.8397, loss = 7.8816\n",
      "Iteration 400: m = 4.6605, b = 0.8398, loss = 7.8815\n",
      "Iteration 401: m = 4.6612, b = 0.8399, loss = 7.8815\n",
      "Iteration 402: m = 4.6620, b = 0.8400, loss = 7.8814\n",
      "Iteration 403: m = 4.6628, b = 0.8401, loss = 7.8813\n",
      "Iteration 404: m = 4.6636, b = 0.8402, loss = 7.8813\n",
      "Iteration 405: m = 4.6643, b = 0.8403, loss = 7.8812\n",
      "Iteration 406: m = 4.6651, b = 0.8404, loss = 7.8812\n",
      "Iteration 407: m = 4.6658, b = 0.8405, loss = 7.8811\n",
      "Iteration 408: m = 4.6665, b = 0.8406, loss = 7.8810\n",
      "Iteration 409: m = 4.6673, b = 0.8407, loss = 7.8810\n",
      "Iteration 410: m = 4.6680, b = 0.8407, loss = 7.8809\n",
      "Iteration 411: m = 4.6687, b = 0.8408, loss = 7.8809\n",
      "Iteration 412: m = 4.6694, b = 0.8409, loss = 7.8808\n",
      "Iteration 413: m = 4.6701, b = 0.8410, loss = 7.8808\n",
      "Iteration 414: m = 4.6708, b = 0.8411, loss = 7.8807\n",
      "Iteration 415: m = 4.6715, b = 0.8412, loss = 7.8807\n",
      "Iteration 416: m = 4.6721, b = 0.8412, loss = 7.8806\n",
      "Iteration 417: m = 4.6728, b = 0.8413, loss = 7.8806\n",
      "Iteration 418: m = 4.6735, b = 0.8414, loss = 7.8806\n",
      "Iteration 419: m = 4.6741, b = 0.8415, loss = 7.8805\n",
      "Iteration 420: m = 4.6748, b = 0.8416, loss = 7.8805\n",
      "Iteration 421: m = 4.6754, b = 0.8416, loss = 7.8804\n",
      "Iteration 422: m = 4.6760, b = 0.8417, loss = 7.8804\n",
      "Iteration 423: m = 4.6767, b = 0.8418, loss = 7.8803\n",
      "Iteration 424: m = 4.6773, b = 0.8419, loss = 7.8803\n",
      "Iteration 425: m = 4.6779, b = 0.8419, loss = 7.8803\n",
      "Iteration 426: m = 4.6785, b = 0.8420, loss = 7.8802\n",
      "Iteration 427: m = 4.6791, b = 0.8421, loss = 7.8802\n",
      "Iteration 428: m = 4.6797, b = 0.8421, loss = 7.8802\n",
      "Iteration 429: m = 4.6803, b = 0.8422, loss = 7.8801\n",
      "Iteration 430: m = 4.6809, b = 0.8423, loss = 7.8801\n",
      "Iteration 431: m = 4.6815, b = 0.8423, loss = 7.8800\n",
      "Iteration 432: m = 4.6820, b = 0.8424, loss = 7.8800\n",
      "Iteration 433: m = 4.6826, b = 0.8425, loss = 7.8800\n",
      "Iteration 434: m = 4.6832, b = 0.8425, loss = 7.8799\n",
      "Iteration 435: m = 4.6837, b = 0.8426, loss = 7.8799\n",
      "Iteration 436: m = 4.6843, b = 0.8427, loss = 7.8799\n",
      "Iteration 437: m = 4.6848, b = 0.8427, loss = 7.8799\n",
      "Iteration 438: m = 4.6854, b = 0.8428, loss = 7.8798\n",
      "Iteration 439: m = 4.6859, b = 0.8429, loss = 7.8798\n",
      "Iteration 440: m = 4.6864, b = 0.8429, loss = 7.8798\n",
      "Iteration 441: m = 4.6869, b = 0.8430, loss = 7.8797\n",
      "Iteration 442: m = 4.6874, b = 0.8430, loss = 7.8797\n",
      "Iteration 443: m = 4.6880, b = 0.8431, loss = 7.8797\n",
      "Iteration 444: m = 4.6885, b = 0.8432, loss = 7.8797\n",
      "Iteration 445: m = 4.6890, b = 0.8432, loss = 7.8796\n",
      "Iteration 446: m = 4.6895, b = 0.8433, loss = 7.8796\n",
      "Iteration 447: m = 4.6900, b = 0.8433, loss = 7.8796\n",
      "Iteration 448: m = 4.6904, b = 0.8434, loss = 7.8796\n",
      "Iteration 449: m = 4.6909, b = 0.8434, loss = 7.8795\n",
      "Iteration 450: m = 4.6914, b = 0.8435, loss = 7.8795\n",
      "Iteration 451: m = 4.6919, b = 0.8435, loss = 7.8795\n",
      "Iteration 452: m = 4.6923, b = 0.8436, loss = 7.8795\n",
      "Iteration 453: m = 4.6928, b = 0.8436, loss = 7.8794\n",
      "Iteration 454: m = 4.6932, b = 0.8437, loss = 7.8794\n",
      "Iteration 455: m = 4.6937, b = 0.8438, loss = 7.8794\n",
      "Iteration 456: m = 4.6941, b = 0.8438, loss = 7.8794\n",
      "Iteration 457: m = 4.6946, b = 0.8439, loss = 7.8794\n",
      "Iteration 458: m = 4.6950, b = 0.8439, loss = 7.8793\n",
      "Iteration 459: m = 4.6955, b = 0.8439, loss = 7.8793\n",
      "Iteration 460: m = 4.6959, b = 0.8440, loss = 7.8793\n",
      "Iteration 461: m = 4.6963, b = 0.8440, loss = 7.8793\n",
      "Iteration 462: m = 4.6967, b = 0.8441, loss = 7.8793\n",
      "Iteration 463: m = 4.6971, b = 0.8441, loss = 7.8792\n",
      "Iteration 464: m = 4.6976, b = 0.8442, loss = 7.8792\n",
      "Iteration 465: m = 4.6980, b = 0.8442, loss = 7.8792\n",
      "Iteration 466: m = 4.6984, b = 0.8443, loss = 7.8792\n",
      "Iteration 467: m = 4.6988, b = 0.8443, loss = 7.8792\n",
      "Iteration 468: m = 4.6992, b = 0.8444, loss = 7.8792\n",
      "Iteration 469: m = 4.6996, b = 0.8444, loss = 7.8791\n",
      "Iteration 470: m = 4.6999, b = 0.8444, loss = 7.8791\n",
      "Iteration 471: m = 4.7003, b = 0.8445, loss = 7.8791\n",
      "Iteration 472: m = 4.7007, b = 0.8445, loss = 7.8791\n",
      "Iteration 473: m = 4.7011, b = 0.8446, loss = 7.8791\n",
      "Iteration 474: m = 4.7015, b = 0.8446, loss = 7.8791\n",
      "Iteration 475: m = 4.7018, b = 0.8446, loss = 7.8791\n",
      "Iteration 476: m = 4.7022, b = 0.8447, loss = 7.8790\n",
      "Iteration 477: m = 4.7025, b = 0.8447, loss = 7.8790\n",
      "Iteration 478: m = 4.7029, b = 0.8448, loss = 7.8790\n",
      "Iteration 479: m = 4.7033, b = 0.8448, loss = 7.8790\n",
      "Iteration 480: m = 4.7036, b = 0.8448, loss = 7.8790\n",
      "Iteration 481: m = 4.7039, b = 0.8449, loss = 7.8790\n",
      "Iteration 482: m = 4.7043, b = 0.8449, loss = 7.8790\n",
      "Iteration 483: m = 4.7046, b = 0.8450, loss = 7.8790\n",
      "Iteration 484: m = 4.7050, b = 0.8450, loss = 7.8789\n",
      "Iteration 485: m = 4.7053, b = 0.8450, loss = 7.8789\n",
      "Iteration 486: m = 4.7056, b = 0.8451, loss = 7.8789\n",
      "Iteration 487: m = 4.7059, b = 0.8451, loss = 7.8789\n",
      "Iteration 488: m = 4.7063, b = 0.8451, loss = 7.8789\n",
      "Iteration 489: m = 4.7066, b = 0.8452, loss = 7.8789\n",
      "Iteration 490: m = 4.7069, b = 0.8452, loss = 7.8789\n",
      "Iteration 491: m = 4.7072, b = 0.8452, loss = 7.8789\n",
      "Iteration 492: m = 4.7075, b = 0.8453, loss = 7.8789\n",
      "Iteration 493: m = 4.7078, b = 0.8453, loss = 7.8789\n",
      "Iteration 494: m = 4.7081, b = 0.8453, loss = 7.8788\n",
      "Iteration 495: m = 4.7084, b = 0.8454, loss = 7.8788\n",
      "Iteration 496: m = 4.7087, b = 0.8454, loss = 7.8788\n",
      "Iteration 497: m = 4.7090, b = 0.8454, loss = 7.8788\n",
      "Iteration 498: m = 4.7093, b = 0.8454, loss = 7.8788\n",
      "Iteration 499: m = 4.7096, b = 0.8455, loss = 7.8788\n",
      "Iteration 500: m = 4.7099, b = 0.8455, loss = 7.8788\n",
      "Iteration 501: m = 4.7102, b = 0.8455, loss = 7.8788\n",
      "Iteration 502: m = 4.7104, b = 0.8456, loss = 7.8788\n",
      "Iteration 503: m = 4.7107, b = 0.8456, loss = 7.8788\n",
      "Iteration 504: m = 4.7110, b = 0.8456, loss = 7.8788\n",
      "Iteration 505: m = 4.7113, b = 0.8456, loss = 7.8788\n",
      "Iteration 506: m = 4.7115, b = 0.8457, loss = 7.8787\n",
      "Iteration 507: m = 4.7118, b = 0.8457, loss = 7.8787\n",
      "Iteration 508: m = 4.7120, b = 0.8457, loss = 7.8787\n",
      "Iteration 509: m = 4.7123, b = 0.8458, loss = 7.8787\n",
      "Iteration 510: m = 4.7126, b = 0.8458, loss = 7.8787\n",
      "Iteration 511: m = 4.7128, b = 0.8458, loss = 7.8787\n",
      "Iteration 512: m = 4.7131, b = 0.8458, loss = 7.8787\n",
      "Iteration 513: m = 4.7133, b = 0.8459, loss = 7.8787\n",
      "Iteration 514: m = 4.7136, b = 0.8459, loss = 7.8787\n",
      "Iteration 515: m = 4.7138, b = 0.8459, loss = 7.8787\n",
      "Iteration 516: m = 4.7140, b = 0.8459, loss = 7.8787\n",
      "Iteration 517: m = 4.7143, b = 0.8460, loss = 7.8787\n",
      "Iteration 518: m = 4.7145, b = 0.8460, loss = 7.8787\n",
      "Iteration 519: m = 4.7148, b = 0.8460, loss = 7.8787\n",
      "Iteration 520: m = 4.7150, b = 0.8460, loss = 7.8787\n",
      "Iteration 521: m = 4.7152, b = 0.8460, loss = 7.8787\n",
      "Iteration 522: m = 4.7154, b = 0.8461, loss = 7.8786\n",
      "Iteration 523: m = 4.7157, b = 0.8461, loss = 7.8786\n",
      "Iteration 524: m = 4.7159, b = 0.8461, loss = 7.8786\n",
      "Iteration 525: m = 4.7161, b = 0.8461, loss = 7.8786\n",
      "Iteration 526: m = 4.7163, b = 0.8462, loss = 7.8786\n",
      "Iteration 527: m = 4.7165, b = 0.8462, loss = 7.8786\n",
      "Iteration 528: m = 4.7168, b = 0.8462, loss = 7.8786\n",
      "Iteration 529: m = 4.7170, b = 0.8462, loss = 7.8786\n",
      "Iteration 530: m = 4.7172, b = 0.8462, loss = 7.8786\n",
      "Iteration 531: m = 4.7174, b = 0.8463, loss = 7.8786\n",
      "Iteration 532: m = 4.7176, b = 0.8463, loss = 7.8786\n",
      "Iteration 533: m = 4.7178, b = 0.8463, loss = 7.8786\n",
      "Iteration 534: m = 4.7180, b = 0.8463, loss = 7.8786\n",
      "Iteration 535: m = 4.7182, b = 0.8463, loss = 7.8786\n",
      "Iteration 536: m = 4.7184, b = 0.8464, loss = 7.8786\n",
      "Iteration 537: m = 4.7186, b = 0.8464, loss = 7.8786\n",
      "Iteration 538: m = 4.7188, b = 0.8464, loss = 7.8786\n",
      "Iteration 539: m = 4.7190, b = 0.8464, loss = 7.8786\n",
      "Iteration 540: m = 4.7191, b = 0.8464, loss = 7.8786\n",
      "Iteration 541: m = 4.7193, b = 0.8464, loss = 7.8786\n",
      "Iteration 542: m = 4.7195, b = 0.8465, loss = 7.8786\n",
      "Iteration 543: m = 4.7197, b = 0.8465, loss = 7.8786\n",
      "Iteration 544: m = 4.7199, b = 0.8465, loss = 7.8786\n",
      "Iteration 545: m = 4.7201, b = 0.8465, loss = 7.8786\n",
      "Iteration 546: m = 4.7202, b = 0.8465, loss = 7.8785\n",
      "Iteration 547: m = 4.7204, b = 0.8465, loss = 7.8785\n",
      "Iteration 548: m = 4.7206, b = 0.8466, loss = 7.8785\n",
      "Iteration 549: m = 4.7208, b = 0.8466, loss = 7.8785\n",
      "Iteration 550: m = 4.7209, b = 0.8466, loss = 7.8785\n",
      "Iteration 551: m = 4.7211, b = 0.8466, loss = 7.8785\n",
      "Iteration 552: m = 4.7213, b = 0.8466, loss = 7.8785\n",
      "Iteration 553: m = 4.7214, b = 0.8466, loss = 7.8785\n",
      "Iteration 554: m = 4.7216, b = 0.8467, loss = 7.8785\n",
      "Iteration 555: m = 4.7218, b = 0.8467, loss = 7.8785\n",
      "Iteration 556: m = 4.7219, b = 0.8467, loss = 7.8785\n",
      "Iteration 557: m = 4.7221, b = 0.8467, loss = 7.8785\n",
      "Iteration 558: m = 4.7222, b = 0.8467, loss = 7.8785\n",
      "Iteration 559: m = 4.7224, b = 0.8467, loss = 7.8785\n",
      "Iteration 560: m = 4.7225, b = 0.8467, loss = 7.8785\n",
      "Iteration 561: m = 4.7227, b = 0.8468, loss = 7.8785\n",
      "Iteration 562: m = 4.7228, b = 0.8468, loss = 7.8785\n",
      "Iteration 563: m = 4.7230, b = 0.8468, loss = 7.8785\n",
      "Iteration 564: m = 4.7231, b = 0.8468, loss = 7.8785\n",
      "Iteration 565: m = 4.7233, b = 0.8468, loss = 7.8785\n",
      "Iteration 566: m = 4.7234, b = 0.8468, loss = 7.8785\n",
      "Iteration 567: m = 4.7236, b = 0.8468, loss = 7.8785\n",
      "Iteration 568: m = 4.7237, b = 0.8469, loss = 7.8785\n",
      "Iteration 569: m = 4.7238, b = 0.8469, loss = 7.8785\n",
      "Iteration 570: m = 4.7240, b = 0.8469, loss = 7.8785\n",
      "Iteration 571: m = 4.7241, b = 0.8469, loss = 7.8785\n",
      "Iteration 572: m = 4.7243, b = 0.8469, loss = 7.8785\n",
      "Iteration 573: m = 4.7244, b = 0.8469, loss = 7.8785\n",
      "Iteration 574: m = 4.7245, b = 0.8469, loss = 7.8785\n",
      "Iteration 575: m = 4.7247, b = 0.8469, loss = 7.8785\n",
      "Iteration 576: m = 4.7248, b = 0.8469, loss = 7.8785\n",
      "Iteration 577: m = 4.7249, b = 0.8470, loss = 7.8785\n",
      "Iteration 578: m = 4.7250, b = 0.8470, loss = 7.8785\n",
      "Iteration 579: m = 4.7252, b = 0.8470, loss = 7.8785\n",
      "Iteration 580: m = 4.7253, b = 0.8470, loss = 7.8785\n",
      "Iteration 581: m = 4.7254, b = 0.8470, loss = 7.8785\n",
      "Iteration 582: m = 4.7255, b = 0.8470, loss = 7.8785\n",
      "Iteration 583: m = 4.7257, b = 0.8470, loss = 7.8785\n",
      "Iteration 584: m = 4.7258, b = 0.8470, loss = 7.8785\n",
      "Iteration 585: m = 4.7259, b = 0.8470, loss = 7.8785\n",
      "Iteration 586: m = 4.7260, b = 0.8471, loss = 7.8785\n",
      "Iteration 587: m = 4.7261, b = 0.8471, loss = 7.8785\n",
      "Iteration 588: m = 4.7262, b = 0.8471, loss = 7.8785\n",
      "Iteration 589: m = 4.7264, b = 0.8471, loss = 7.8785\n",
      "Iteration 590: m = 4.7265, b = 0.8471, loss = 7.8785\n",
      "Iteration 591: m = 4.7266, b = 0.8471, loss = 7.8785\n",
      "Iteration 592: m = 4.7267, b = 0.8471, loss = 7.8785\n",
      "Iteration 593: m = 4.7268, b = 0.8471, loss = 7.8785\n",
      "Iteration 594: m = 4.7269, b = 0.8471, loss = 7.8785\n",
      "Iteration 595: m = 4.7270, b = 0.8471, loss = 7.8785\n",
      "Iteration 596: m = 4.7271, b = 0.8471, loss = 7.8784\n",
      "Iteration 597: m = 4.7272, b = 0.8472, loss = 7.8784\n",
      "Iteration 598: m = 4.7273, b = 0.8472, loss = 7.8784\n",
      "Iteration 599: m = 4.7274, b = 0.8472, loss = 7.8784\n",
      "Iteration 600: m = 4.7275, b = 0.8472, loss = 7.8784\n",
      "Iteration 601: m = 4.7276, b = 0.8472, loss = 7.8784\n",
      "Iteration 602: m = 4.7277, b = 0.8472, loss = 7.8784\n",
      "Iteration 603: m = 4.7278, b = 0.8472, loss = 7.8784\n",
      "Iteration 604: m = 4.7279, b = 0.8472, loss = 7.8784\n",
      "Iteration 605: m = 4.7280, b = 0.8472, loss = 7.8784\n",
      "Iteration 606: m = 4.7281, b = 0.8472, loss = 7.8784\n",
      "Iteration 607: m = 4.7282, b = 0.8472, loss = 7.8784\n",
      "Iteration 608: m = 4.7283, b = 0.8472, loss = 7.8784\n",
      "Iteration 609: m = 4.7284, b = 0.8473, loss = 7.8784\n",
      "Iteration 610: m = 4.7285, b = 0.8473, loss = 7.8784\n",
      "Iteration 611: m = 4.7286, b = 0.8473, loss = 7.8784\n",
      "Iteration 612: m = 4.7287, b = 0.8473, loss = 7.8784\n",
      "Iteration 613: m = 4.7288, b = 0.8473, loss = 7.8784\n",
      "Iteration 614: m = 4.7288, b = 0.8473, loss = 7.8784\n",
      "Iteration 615: m = 4.7289, b = 0.8473, loss = 7.8784\n",
      "Iteration 616: m = 4.7290, b = 0.8473, loss = 7.8784\n",
      "Iteration 617: m = 4.7291, b = 0.8473, loss = 7.8784\n",
      "Iteration 618: m = 4.7292, b = 0.8473, loss = 7.8784\n",
      "Iteration 619: m = 4.7293, b = 0.8473, loss = 7.8784\n",
      "Iteration 620: m = 4.7294, b = 0.8473, loss = 7.8784\n",
      "Iteration 621: m = 4.7294, b = 0.8473, loss = 7.8784\n",
      "Iteration 622: m = 4.7295, b = 0.8473, loss = 7.8784\n",
      "Iteration 623: m = 4.7296, b = 0.8474, loss = 7.8784\n",
      "Iteration 624: m = 4.7297, b = 0.8474, loss = 7.8784\n",
      "Iteration 625: m = 4.7298, b = 0.8474, loss = 7.8784\n",
      "Iteration 626: m = 4.7298, b = 0.8474, loss = 7.8784\n",
      "Iteration 627: m = 4.7299, b = 0.8474, loss = 7.8784\n",
      "Iteration 628: m = 4.7300, b = 0.8474, loss = 7.8784\n",
      "Iteration 629: m = 4.7301, b = 0.8474, loss = 7.8784\n",
      "Iteration 630: m = 4.7301, b = 0.8474, loss = 7.8784\n",
      "Iteration 631: m = 4.7302, b = 0.8474, loss = 7.8784\n",
      "Iteration 632: m = 4.7303, b = 0.8474, loss = 7.8784\n",
      "Iteration 633: m = 4.7304, b = 0.8474, loss = 7.8784\n",
      "Iteration 634: m = 4.7304, b = 0.8474, loss = 7.8784\n",
      "Iteration 635: m = 4.7305, b = 0.8474, loss = 7.8784\n",
      "Iteration 636: m = 4.7306, b = 0.8474, loss = 7.8784\n",
      "Iteration 637: m = 4.7306, b = 0.8474, loss = 7.8784\n",
      "Iteration 638: m = 4.7307, b = 0.8474, loss = 7.8784\n",
      "Iteration 639: m = 4.7308, b = 0.8474, loss = 7.8784\n",
      "Iteration 640: m = 4.7308, b = 0.8474, loss = 7.8784\n",
      "Iteration 641: m = 4.7309, b = 0.8475, loss = 7.8784\n",
      "Iteration 642: m = 4.7310, b = 0.8475, loss = 7.8784\n",
      "Iteration 643: m = 4.7310, b = 0.8475, loss = 7.8784\n",
      "Iteration 644: m = 4.7311, b = 0.8475, loss = 7.8784\n",
      "Iteration 645: m = 4.7312, b = 0.8475, loss = 7.8784\n",
      "Iteration 646: m = 4.7312, b = 0.8475, loss = 7.8784\n",
      "Iteration 647: m = 4.7313, b = 0.8475, loss = 7.8784\n",
      "Iteration 648: m = 4.7314, b = 0.8475, loss = 7.8784\n",
      "Iteration 649: m = 4.7314, b = 0.8475, loss = 7.8784\n",
      "Iteration 650: m = 4.7315, b = 0.8475, loss = 7.8784\n",
      "Iteration 651: m = 4.7315, b = 0.8475, loss = 7.8784\n",
      "Iteration 652: m = 4.7316, b = 0.8475, loss = 7.8784\n",
      "Iteration 653: m = 4.7317, b = 0.8475, loss = 7.8784\n",
      "Iteration 654: m = 4.7317, b = 0.8475, loss = 7.8784\n",
      "Iteration 655: m = 4.7318, b = 0.8475, loss = 7.8784\n",
      "Iteration 656: m = 4.7318, b = 0.8475, loss = 7.8784\n",
      "Iteration 657: m = 4.7319, b = 0.8475, loss = 7.8784\n",
      "Iteration 658: m = 4.7319, b = 0.8475, loss = 7.8784\n",
      "Iteration 659: m = 4.7320, b = 0.8475, loss = 7.8784\n",
      "Iteration 660: m = 4.7321, b = 0.8475, loss = 7.8784\n",
      "Iteration 661: m = 4.7321, b = 0.8475, loss = 7.8784\n",
      "Iteration 662: m = 4.7322, b = 0.8475, loss = 7.8784\n",
      "Iteration 663: m = 4.7322, b = 0.8475, loss = 7.8784\n",
      "Iteration 664: m = 4.7323, b = 0.8476, loss = 7.8784\n",
      "Iteration 665: m = 4.7323, b = 0.8476, loss = 7.8784\n",
      "Iteration 666: m = 4.7324, b = 0.8476, loss = 7.8784\n",
      "Iteration 667: m = 4.7324, b = 0.8476, loss = 7.8784\n",
      "Iteration 668: m = 4.7325, b = 0.8476, loss = 7.8784\n",
      "Iteration 669: m = 4.7325, b = 0.8476, loss = 7.8784\n",
      "Iteration 670: m = 4.7326, b = 0.8476, loss = 7.8784\n",
      "Iteration 671: m = 4.7326, b = 0.8476, loss = 7.8784\n",
      "Iteration 672: m = 4.7327, b = 0.8476, loss = 7.8784\n",
      "Iteration 673: m = 4.7327, b = 0.8476, loss = 7.8784\n",
      "Iteration 674: m = 4.7328, b = 0.8476, loss = 7.8784\n",
      "Iteration 675: m = 4.7328, b = 0.8476, loss = 7.8784\n",
      "Iteration 676: m = 4.7329, b = 0.8476, loss = 7.8784\n",
      "Iteration 677: m = 4.7329, b = 0.8476, loss = 7.8784\n",
      "Iteration 678: m = 4.7330, b = 0.8476, loss = 7.8784\n",
      "Iteration 679: m = 4.7330, b = 0.8476, loss = 7.8784\n",
      "Iteration 680: m = 4.7330, b = 0.8476, loss = 7.8784\n",
      "Iteration 681: m = 4.7331, b = 0.8476, loss = 7.8784\n",
      "Iteration 682: m = 4.7331, b = 0.8476, loss = 7.8784\n",
      "Iteration 683: m = 4.7332, b = 0.8476, loss = 7.8784\n",
      "Iteration 684: m = 4.7332, b = 0.8476, loss = 7.8784\n",
      "Iteration 685: m = 4.7333, b = 0.8476, loss = 7.8784\n",
      "Iteration 686: m = 4.7333, b = 0.8476, loss = 7.8784\n",
      "Iteration 687: m = 4.7333, b = 0.8476, loss = 7.8784\n",
      "Iteration 688: m = 4.7334, b = 0.8476, loss = 7.8784\n",
      "Iteration 689: m = 4.7334, b = 0.8476, loss = 7.8784\n",
      "Iteration 690: m = 4.7335, b = 0.8476, loss = 7.8784\n",
      "Iteration 691: m = 4.7335, b = 0.8476, loss = 7.8784\n",
      "Iteration 692: m = 4.7335, b = 0.8476, loss = 7.8784\n",
      "Iteration 693: m = 4.7336, b = 0.8476, loss = 7.8784\n",
      "Iteration 694: m = 4.7336, b = 0.8476, loss = 7.8784\n",
      "Iteration 695: m = 4.7337, b = 0.8476, loss = 7.8784\n",
      "Iteration 696: m = 4.7337, b = 0.8476, loss = 7.8784\n",
      "Iteration 697: m = 4.7337, b = 0.8477, loss = 7.8784\n",
      "Iteration 698: m = 4.7338, b = 0.8477, loss = 7.8784\n",
      "Iteration 699: m = 4.7338, b = 0.8477, loss = 7.8784\n",
      "Iteration 700: m = 4.7338, b = 0.8477, loss = 7.8784\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descend for Linear Regression\n",
    "# y_predicted will be calculated as: y_predicted = m * x + b, where m is the slope and b is the y-intercept.\n",
    "# for the loss function, we will use Mean Squared Error (MSE).\n",
    "# For the sake of simplifing the differentiation, we will define the loss function as: loss = ((y - y_predicted) ** 2) / 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data points (x, y)\n",
    "x = np.random.randn(100)  # 100 random data points for x\n",
    "y = 5.0 * x + 1.0 + np.random.randn(100) * 4  # y = 2x + 1 with some noise to simulate real-world data\n",
    "                                                # the predicted parameters should be close to m=2.0 and b=1.0\n",
    "\n",
    "# Initializing the parameters\n",
    "m = 0.0  # slope\n",
    "b = 0.0  # y-intercept\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.01 # Adjust as needed, just not too high or too low, and definitely not 0 (which would mean no learning)\n",
    "\n",
    "def descend(x, y, m, b, learning_rate):\n",
    "    n = len(y)  # number of data points\n",
    "    y_predicted = m * x + b  # predicted values\n",
    "    loss = np.mean((y - y_predicted) ** 2) / 2  # Mean Squared Error, which is our loss function: ((y - mx - b) ** 2) / 2\n",
    "\n",
    "    dm = 0.0  # gradient with respect to m\n",
    "    db = 0.0  # gradient with respect to b\n",
    "\n",
    "    # Calculate gradients\n",
    "    dm = (-1/n) * np.sum(x * (y - y_predicted))  # gradient with respect to m\n",
    "    db = (-1/n) * np.sum(y - y_predicted)        # gradient with respect to b\n",
    "\n",
    "    # Update parameters\n",
    "    m -= learning_rate * dm\n",
    "    b -= learning_rate * db\n",
    "\n",
    "    return m, b, loss\n",
    "\n",
    "# Iterate to optimize parameters\n",
    "for i in range(700): # number of iterations, you can adjust this number based on how well the model is converging\n",
    "    m, b, loss = descend(x, y, m, b, learning_rate)  # perform one step of gradient descent\n",
    "    print(f\"Iteration {i + 1}: m = {m:.4f}, b = {b:.4f}, loss = {loss:.4f}\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c31c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn model: m = 4.7374, b = 0.8478\n",
      "Sklearn loss: 7.8784\n",
      "Custom model: m = 4.7338, b = 0.8477, loss = 7.8784\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now for the sklearn linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and fit the model using sklearn\n",
    "model = LinearRegression()\n",
    "X = x.reshape(-1, 1)  # reshape x to be a 2D array for sklearn\n",
    "model.fit(X, y) \n",
    "y_predicted_sklearn = model.predict(X)  # predict using the sklearn model\n",
    "\n",
    "# Compare the results\n",
    "print(f\"Sklearn model: m = {model.coef_[0]:.4f}, b = {model.intercept_:.4f}\")\n",
    "print(f\"Sklearn loss: {np.mean((y - y_predicted_sklearn) ** 2) / 2:.4f}\")\n",
    "\n",
    "print(f\"Custom model: m = {m:.4f}, b = {b:.4f}, loss = {loss:.4f}\")\n",
    "\n",
    "plt.scatter(x, y, label='Data Points', color='blue')  # plot the original data points\n",
    "plt.plot(x, m * x + b, color='red', label='Fitted Line')  # plot the fitted line\n",
    "plt.plot(x, y_predicted_sklearn, color='green', linestyle='--', label='Sklearn Fitted Line')  # plot the sklearn fitted line\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression with Gradient Descent')\n",
    "plt.legend()\n",
    "plt.show()  # display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
